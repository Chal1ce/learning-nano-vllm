# Nano-vLLM 项目架构深度解析

## 📚 目录

### 1. [项目概述](01_项目概述.md)
- 项目简介与特点
- 整体架构概览
- 核心设计理念
- 与vLLM的对比

### 2. [项目结构分析](02_项目结构分析.md)
- 目录结构解析
- 模块职责划分
- 依赖关系梳理
- 配置系统解析

### 3. [核心引擎模块](03_核心引擎模块.md)
- LLMEngine: 大脑控制器
- Scheduler: 智能调度器
- ModelRunner: 模型执行器
- Sequence: 请求生命周期管理
- BlockManager: 内存管理大师

### 4. [模型实现层](04_模型实现层.md)
- Qwen3模型架构
- Transformer层实现
- 注意力机制深度解析
- 模型并行策略

### 5. [算子优化层](05_算子优化层.md)
- 线性层优化
- 注意力算子优化
- Flash Attention集成
- Triton内核优化

### 6. [推理调度系统](06_推理调度系统.md)
- 请求队列管理
- Prefill与Decode策略
- 批处理优化
- 内存与计算平衡

### 7. [内存管理机制](07_内存管理机制.md)
- KV Cache设计
- Prefix Caching优化
- 块分配算法
- 内存复用策略

### 8. [并行计算架构](08_并行计算架构.md)
- Tensor Parallel实现
- 多进程通信
- CUDA Graph优化
- 分布式协调

### 9. [采样与生成](09_采样与生成.md)
- 采样算法实现
- 温度控制策略
- 高效采样算子
- 生成终止条件

### 10. [性能优化技术](10_性能优化技术.md)
- 推理加速技术
- 内存使用优化
- 计算图优化
- 吞吐量提升策略

### 11. [使用示例与最佳实践](11_使用示例与最佳实践.md)
- 基本使用方法
- 性能调优指南
- 常见问题解决
- 扩展开发指导

### 12. [项目总结与思考](12_项目总结与思考.md)
- 设计亮点总结
- 技术创新点
- 学习价值分析
- 未来发展方向

---

## 🎯 学习路径建议

1. **入门路径**: 1 → 2 → 3 → 11（了解整体架构和基本使用）
2. **深度路径**: 4 → 5 → 6 → 7（深入核心实现）
3. **优化路径**: 8 → 9 → 10（掌握性能优化技术）
4. **全面路径**: 按章节顺序阅读，完整理解整个系统

---

## 🔍 核心概念

- **LLMEngine**: 整个推理引擎的核心控制器
- **Scheduler**: 负责请求调度和批处理
- **ModelRunner**: 模型前向推理执行器
- **Sequence**: 单个推理请求的抽象
- **BlockManager**: KV Cache内存管理器
- **Prefix Caching**: 前缀缓存优化技术
- **Tensor Parallel**: 张量并行计算
- **CUDA Graph**: CUDA图优化技术

---

## 💡 阅读提示

- 每个章节都包含理论解释、代码分析和实际示例
- 重点关注模块间的交互和数据流
- 结合代码理解设计思想和优化策略
- 建议边阅读边运行示例代码加深理解