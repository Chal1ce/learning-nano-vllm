<div align="center">

# ğŸ“ Learning Nano-vLLM

**æ·±å…¥å­¦ä¹  Nano-vLLM æ¨ç†å¼•æ“çš„å®Œæ•´æŒ‡å—**

*A Comprehensive Guide to Understanding Nano-vLLM Inference Engine*

[![GitHub stars](https://img.shields.io/github/stars/Chal1ce/learning-nano-vllm?style=social)](https://github.com/Chal1ce/learning-nano-vllm/stargazers)
[![GitHub forks](https://img.shields.io/github/forks/Chal1ce/learning-nano-vllm?style=social)](https://github.com/Chal1ce/learning-nano-vllm/network/members)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Nano-vLLM Version](https://img.shields.io/badge/nano--vllm-0.11.2-green.svg)](https://github.com/GeeeekExplorer/nano-vllm)

[ğŸ“š ä¸­æ–‡æ–‡æ¡£](#ä¸­æ–‡ç‰ˆæœ¬) | [ğŸ“– English Docs](#english-version) | [ğŸ”— Wiki](https://github.com/Chal1ce/learning-nano-vllm/tree/main/nano-vllm-main/UnderstandArch)

</div>

---

## ğŸ“– ä¸­æ–‡ç‰ˆæœ¬

### ğŸŒŸ é¡¹ç›®ç®€ä»‹

æœ¬ä»“åº“æä¾›äº†å¯¹ **nano-vLLM 0.11.2** çš„æ·±åº¦è§£æå’Œå­¦ä¹ èµ„æ–™ï¼Œæ—¨åœ¨å¸®åŠ©å¼€å‘è€…å…¨é¢ç†è§£ç°ä»£ LLM æ¨ç†ç³»ç»Ÿçš„æ¶æ„è®¾è®¡ã€æ ¸å¿ƒæŠ€æœ¯å’Œä¼˜åŒ–ç­–ç•¥ã€‚

é€šè¿‡ç³»ç»ŸåŒ–çš„å­¦ä¹ è·¯å¾„å’Œè¯¦ç»†çš„æŠ€æœ¯æ–‡æ¡£ï¼Œä½ å°†æŒæ¡ï¼š
- ğŸ—ï¸ LLM æ¨ç†å¼•æ“çš„æ¶æ„è®¾è®¡åŸç†
- âš¡ é«˜æ€§èƒ½æ¨ç†ä¼˜åŒ–æŠ€æœ¯
- ğŸ”§ å®æˆ˜éƒ¨ç½²å’Œè°ƒä¼˜ç»éªŒ
- ğŸš€ å‰æ²¿æŠ€æœ¯å’Œåˆ›æ–°æ–¹å‘

### ğŸ“š æ ¸å¿ƒå†…å®¹

#### ğŸ“– å®Œæ•´çš„å­¦ä¹ æ–‡æ¡£
åŒ…å« **12 ä¸ªç« èŠ‚** çš„æ·±åº¦æŠ€æœ¯è§£æï¼Œæ¶µç›–ä»åŸºç¡€åˆ°é«˜çº§çš„å®Œæ•´å­¦ä¹ è·¯å¾„ï¼š

- **åŸºç¡€ç†è§£ç¯‡**ï¼ˆç¬¬ 1-3 ç« ï¼‰ï¼šé¡¹ç›®æ¦‚è¿°ã€ç»“æ„åˆ†æã€æ ¸å¿ƒå¼•æ“
- **æ·±å…¥åˆ†æç¯‡**ï¼ˆç¬¬ 4-6 ç« ï¼‰ï¼šæ¨¡å‹å®ç°ã€ç®—å­ä¼˜åŒ–ã€è°ƒåº¦æ‰§è¡Œ
- **ç³»ç»ŸæŒæ¡ç¯‡**ï¼ˆç¬¬ 7-9 ç« ï¼‰ï¼šå¹¶å‘æ§åˆ¶ã€æ¶æ„è®¾è®¡ã€æ€§èƒ½æµ‹è¯•
- **å®æˆ˜åº”ç”¨ç¯‡**ï¼ˆç¬¬ 10-12 ç« ï¼‰ï¼šéƒ¨ç½²æŒ‡å—ã€æŠ€æœ¯åˆ›æ–°ã€æ€»ç»“è§„åˆ’

#### ğŸ¯ æŠ€æœ¯äº®ç‚¹

| ç‰¹æ€§ | è¯´æ˜ |
|------|------|
| ğŸš€ **Prefix ç¼“å­˜** | æ™ºèƒ½å¤ç”¨ KV ç¼“å­˜ï¼Œå‡å°‘ 30-70% é‡å¤è®¡ç®— |
| âš¡ **ä¸¤é˜¶æ®µè°ƒåº¦** | Prefill/Decode åˆ†ç¦»ï¼Œä¼˜åŒ–ç”¨æˆ·ä½“éªŒ |
| ğŸ’¾ **é«˜æ•ˆ KV ç®¡ç†** | ç²¾ç»†åŒ–å—ç®¡ç†ï¼Œæå‡ 40-60% å†…å­˜åˆ©ç”¨ç‡ |
| ğŸ”¥ **æ€§èƒ½ä¼˜åŒ–** | CUDA Graphã€ç®—å­èåˆã€æµæ°´çº¿ä¼˜åŒ– |

### ğŸš€ å¿«é€Ÿå¼€å§‹

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/Chal1ce/learning-nano-vllm.git
cd learning-nano-vllm

# æŸ¥çœ‹è¯¦ç»†æ–‡æ¡£
cd nano-vllm-main/UnderstandArch
```

### ğŸ“– è¯¦ç»†æ–‡æ¡£

è®¿é—®æˆ‘ä»¬çš„ [Wiki æ–‡æ¡£](https://github.com/Chal1ce/learning-nano-vllm/tree/main/nano-vllm-main/UnderstandArch) è·å–å®Œæ•´çš„å­¦ä¹ èµ„æ–™ï¼ŒåŒ…æ‹¬ï¼š

- ğŸ“ 12 ç« èŠ‚è¯¦ç»†æŠ€æœ¯è§£æ
- ğŸ¯ æ¨èå­¦ä¹ è·¯å¾„è§„åˆ’
- ğŸ’¡ å®è·µé¡¹ç›®å’Œæ¡ˆä¾‹
- ğŸ”¬ å‰æ²¿ç ”ç©¶æ–¹å‘

### ğŸ“ é€‚åˆäººç¾¤

- ğŸ§‘â€ğŸ’» AI/ML å·¥ç¨‹å¸ˆ
- ğŸ—ï¸ ç³»ç»Ÿæ¶æ„å¸ˆ
- ğŸ”¬ æŠ€æœ¯ç ”ç©¶å‘˜
- ğŸ‘¨â€ğŸ“ æ·±åº¦å­¦ä¹ çˆ±å¥½è€…

### ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ª â­ Star æ”¯æŒä¸€ä¸‹ï¼

---

## ğŸ“– English Version

### ğŸŒŸ Introduction

This repository provides in-depth analysis and learning materials for **nano-vLLM 0.11.2**, helping developers comprehensively understand the architecture, core technologies, and optimization strategies of modern LLM inference systems.

Through a systematic learning path and detailed technical documentation, you will master:
- ğŸ—ï¸ Architectural design principles of LLM inference engines
- âš¡ High-performance inference optimization techniques
- ğŸ”§ Practical deployment and tuning experience
- ğŸš€ Cutting-edge technologies and innovation directions

### ğŸ“š Core Content

#### ğŸ“– Complete Learning Documentation
Contains **12 chapters** of in-depth technical analysis, covering a complete learning path from basics to advanced:

- **Foundation** (Chapters 1-3): Overview, Structure Analysis, Core Engine
- **Deep Dive** (Chapters 4-6): Model Implementation, Operator Optimization, Scheduling
- **System Mastery** (Chapters 7-9): Concurrency Control, Architecture Design, Performance Testing
- **Practical Application** (Chapters 10-12): Deployment Guide, Innovation, Summary

#### ğŸ¯ Technical Highlights

| Feature | Description |
|---------|-------------|
| ğŸš€ **Prefix Caching** | Smart KV cache reuse, reducing 30-70% redundant computation |
| âš¡ **Two-Stage Scheduling** | Separated Prefill/Decode for optimized UX |
| ğŸ’¾ **Efficient KV Management** | Fine-grained block management, 40-60% memory efficiency boost |
| ğŸ”¥ **Performance Optimization** | CUDA Graph, operator fusion, pipeline optimization |

### ğŸš€ Quick Start

```bash
# Clone the repository
git clone https://github.com/Chal1ce/learning-nano-vllm.git
cd learning-nano-vllm

# View detailed documentation
cd nano-vllm-main/UnderstandArch
```

### ğŸ“– Documentation

Visit our [Wiki Documentation](https://github.com/Chal1ce/learning-nano-vllm/tree/main/nano-vllm-main/UnderstandArch) for complete learning materials, including:

- ğŸ“ 12 chapters of detailed technical analysis
- ğŸ¯ Recommended learning path planning
- ğŸ’¡ Practical projects and case studies
- ğŸ”¬ Cutting-edge research directions

### ğŸ“ Target Audience

- ğŸ§‘â€ğŸ’» AI/ML Engineers
- ğŸ—ï¸ System Architects
- ğŸ”¬ Technical Researchers
- ğŸ‘¨â€ğŸ“ Deep Learning Enthusiasts

### ğŸ¤ Contributing

Issues and Pull Requests are welcome! If this project helps you, please give it a â­ Star!

---

<div align="center">

### ğŸ“ è”ç³»æ–¹å¼ | Contact

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œæ¬¢è¿é€šè¿‡ [Issues](https://github.com/Chal1ce/learning-nano-vllm/issues) è”ç³»æˆ‘ä»¬

For questions or suggestions, feel free to contact us via [Issues](https://github.com/Chal1ce/learning-nano-vllm/issues)

---

**ğŸ“š åŸºäº nano-vLLM 0.11.2 | Based on nano-vLLM 0.11.2**

Made with â¤ï¸ by [Chal1ce](https://github.com/Chal1ce)

</div>
